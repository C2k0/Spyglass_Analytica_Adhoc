{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey Data Processor\n",
    "\n",
    "This notebook processes survey data from SQL query files and generates combined outputs for analysis.\n",
    "\n",
    "## Overview\n",
    "- Reads SQL query files for each survey\n",
    "- Executes queries to load survey data\n",
    "- Applies custom transformations\n",
    "- Outputs combined files with NPS and driver scores\n",
    "- Generates comprehensive dataset with all survey columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from shared.metrics.common_metrics import *\n",
    "from shared.utils.data_validator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "### Survey Configuration\n",
    "Add your survey names here. Each survey should have a corresponding `.sql` file in the `data/raw/` directory."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Survey Configuration - Update this list with your survey names\nSURVEYS = [\n    \"PRISM\",\n    \"Customer_Satisfaction_Q1\", \n    \"Employee_Engagement_2024\",\n    \"Product_Feedback_Survey\",\n    \"Brand_Perception_Study\"\n]\n\n# Allowed Column Types\nALLOWED_COLUMN_TYPES = [\n    \"STANDARD\",      # Required fields for identification and timestamps\n    \"LTR\",          # Likelihood to Recommend (NPS) related columns\n    \"DRIVERS\",      # Driver/satisfaction scores and metrics\n    \"METADATA\"      # Demographics, comments, and supplementary data\n]\n\n# All Columns Dictionary - Column name mapped to column type\nALL_COLUMNS = {\n    \"ResponseID\": \"STANDARD\",\n    \"Timestamp\": \"STANDARD\", \n    \"NPS_Score\": \"LTR\",\n    \"NPS_Comment\": \"LTR\",\n    \"Satisfaction_Rating\": \"DRIVERS\",\n    \"Satisfaction_Comment\": \"DRIVERS\",\n    \"Custom_Metric_1\": \"DRIVERS\",\n    \"Custom_Metric_2\": \"DRIVERS\",\n    \"Custom_Metric_3\": \"DRIVERS\",\n    \"Custom_Metric_4\": \"DRIVERS\",\n    \"Custom_Metric_5\": \"DRIVERS\",\n    \"Demographics_Age\": \"METADATA\",\n    \"Demographics_Role\": \"METADATA\",\n    \"Demographics_Location\": \"METADATA\",\n    \"Free_Text_Feedback\": \"METADATA\"\n}\n\n# Validate that all column types are allowed\ninvalid_types = set(ALL_COLUMNS.values()) - set(ALLOWED_COLUMN_TYPES)\nif invalid_types:\n    raise ValueError(f\"Invalid column types found: {invalid_types}. Must be one of: {ALLOWED_COLUMN_TYPES}\")\n\n# File paths\nSQL_DIR = \"../data/raw/\"\nOUTPUT_DIR = \"../data/processed/\"\nTIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n# Ensure output directory exists\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"Processing {len(SURVEYS)} surveys:\")\nfor i, survey in enumerate(SURVEYS, 1):\n    print(f\"  {i}. {survey}\")\n\nprint(f\"\\nColumn Types ({len(ALLOWED_COLUMN_TYPES)}):\")\nfor i, col_type in enumerate(ALLOWED_COLUMN_TYPES, 1):\n    cols_of_type = [col for col, ctype in ALL_COLUMNS.items() if ctype == col_type]\n    print(f\"  {i}. {col_type}: {len(cols_of_type)} columns\")\n\nprint(f\"\\nAll Columns ({len(ALL_COLUMNS)}):\")\nfor col_type in ALLOWED_COLUMN_TYPES:\n    cols_of_type = [col for col, ctype in ALL_COLUMNS.items() if ctype == col_type]\n    print(f\"  {col_type}:\")\n    for col in cols_of_type:\n        print(f\"    - {col}\")\n    print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def validate_columns(df, survey_name, all_columns_dict):\n    \"\"\"\n    Validate that all columns in the DataFrame are in the allowed columns dictionary.\n    \n    Args:\n        df (pd.DataFrame): Survey data\n        survey_name (str): Name of the survey\n        all_columns_dict (dict): Dictionary of allowed column names and their types\n    \n    Returns:\n        tuple: (is_valid, invalid_columns)\n    \"\"\"\n    # Exclude automatically added columns from validation\n    auto_added_columns = {'Survey_Name', 'Processed_Date'}\n    df_columns = set(df.columns) - auto_added_columns\n    allowed_columns = set(all_columns_dict.keys())\n    \n    invalid_columns = df_columns - allowed_columns\n    \n    if invalid_columns:\n        print(f\"  ✗ VALIDATION FAILED for {survey_name}\")\n        print(f\"    Invalid columns: {sorted(invalid_columns)}\")\n        print(f\"    Valid columns must be from: {sorted(allowed_columns)}\")\n        return False, invalid_columns\n    else:\n        print(f\"  ✓ Column validation passed for {survey_name}\")\n        return True, set()\n\ndef load_sql_query(survey_name):\n    \"\"\"\n    Load SQL query from file for a given survey.\n    \n    Args:\n        survey_name (str): Name of the survey\n    \n    Returns:\n        str: SQL query string\n    \"\"\"\n    sql_file_path = os.path.join(SQL_DIR, f\"{survey_name}.sql\")\n    \n    if not os.path.exists(sql_file_path):\n        raise FileNotFoundError(f\"SQL file not found: {sql_file_path}\")\n    \n    with open(sql_file_path, 'r', encoding='utf-8') as file:\n        query = file.read().strip()\n    \n    return query\n\ndef execute_query_and_load_data(survey_name, connection=None):\n    \"\"\"\n    Execute SQL query and load data for a survey.\n    \n    Args:\n        survey_name (str): Name of the survey\n        connection: Database connection (if None, will create SQLite connection)\n    \n    Returns:\n        pd.DataFrame: Survey data\n    \"\"\"\n    query = load_sql_query(survey_name)\n    \n    # If no connection provided, create a simple SQLite connection\n    # Note: Update this section based on your actual database configuration\n    if connection is None:\n        # For demonstration - replace with your actual database connection\n        conn = sqlite3.connect(':memory:')\n        print(f\"Warning: Using in-memory SQLite for {survey_name}. Update connection for production.\")\n    else:\n        conn = connection\n    \n    try:\n        df = pd.read_sql_query(query, conn)\n        \n        # Validate columns before processing\n        is_valid, invalid_cols = validate_columns(df, survey_name, ALL_COLUMNS)\n        if not is_valid:\n            print(f\"  ✗ Skipping {survey_name} due to column validation failure\")\n            return None\n        \n        df['Survey_Name'] = survey_name  # Add survey identifier\n        print(f\"✓ Loaded {len(df)} records from {survey_name}\")\n        return df\n    except Exception as e:\n        print(f\"✗ Error loading data for {survey_name}: {str(e)}\")\n        return None\n    finally:\n        if connection is None and 'conn' in locals():\n            conn.close()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for processed data\n",
    "all_survey_data = []\n",
    "nps_driver_data = []\n",
    "processing_summary = []\n",
    "\n",
    "print(\"Starting data processing pipeline...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Process each survey\nfor survey_name in SURVEYS:\n    print(f\"Processing survey: {survey_name}\")\n    print(\"-\" * 50)\n    \n    try:\n        # Load data from SQL query\n        df = execute_query_and_load_data(survey_name)\n        \n        if df is not None and len(df) > 0:\n            # Store original data structure info\n            original_shape = df.shape\n            original_columns = list(df.columns)\n            \n            # === CUSTOM TRANSFORMATIONS SECTION ===\n            # TODO: Add your custom transformations here\n            # Examples:\n            # - Data cleaning and validation\n            # - Column renaming/standardization\n            # - Derived field calculations\n            # - Data type conversions\n            \n            print(f\"  Original shape: {original_shape}\")\n            print(f\"  Columns: {len(original_columns)}\")\n            \n            # Add processing timestamp\n            df['Processed_Date'] = datetime.now()\n            \n            # Store full dataset\n            all_survey_data.append(df.copy())\n            \n            # Extract LTR and driver scores if available\n            ltr_driver_subset = extract_ltr_and_drivers(df, survey_name, ALL_COLUMNS)\n            if ltr_driver_subset is not None:\n                nps_driver_data.append(ltr_driver_subset)\n            \n            # Record processing summary\n            processing_summary.append({\n                'Survey_Name': survey_name,\n                'Records_Processed': len(df),\n                'Columns_Count': len(df.columns),\n                'Has_LTR_Data': any(ALL_COLUMNS.get(col) == \"LTR\" for col in df.columns),\n                'Has_Driver_Data': any(ALL_COLUMNS.get(col) == \"DRIVERS\" for col in df.columns),\n                'Column_Validation': 'Passed',\n                'Processing_Status': 'Success',\n                'Processed_Time': datetime.now()\n            })\n            \n            print(f\"  ✓ Successfully processed {len(df)} records\")\n            \n        else:\n            status = 'Column Validation Failed' if df is None else 'No Data'\n            print(f\"  ✗ {status} for {survey_name}\")\n            processing_summary.append({\n                'Survey_Name': survey_name,\n                'Records_Processed': 0,\n                'Columns_Count': 0,\n                'Has_LTR_Data': False,\n                'Has_Driver_Data': False,\n                'Column_Validation': 'Failed' if df is None else 'N/A',\n                'Processing_Status': status,\n                'Processed_Time': datetime.now()\n            })\n            \n    except Exception as e:\n        print(f\"  ✗ Error processing {survey_name}: {str(e)}\")\n        processing_summary.append({\n            'Survey_Name': survey_name,\n            'Records_Processed': 0,\n            'Columns_Count': 0,\n            'Has_LTR_Data': False,\n            'Has_Driver_Data': False,\n            'Column_Validation': 'Error',\n            'Processing_Status': f'Error: {str(e)}',\n            'Processed_Time': datetime.now()\n        })\n    \n    print(\"\\n\")\n\nprint(f\"Data processing complete. Processed {len(all_survey_data)} surveys successfully.\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def extract_ltr_and_drivers(df, survey_name, all_columns_dict):\n    \"\"\"\n    Extract LTR (Likelihood to Recommend) and driver scores from survey data.\n    \n    Args:\n        df (pd.DataFrame): Survey data\n        survey_name (str): Name of the survey\n        all_columns_dict (dict): Dictionary mapping column names to types\n    \n    Returns:\n        pd.DataFrame or None: Subset with LTR and driver data\n    \"\"\"\n    # Get LTR and DRIVERS columns from the column type mapping\n    ltr_columns = [col for col, col_type in all_columns_dict.items() \n                   if col_type == \"LTR\" and col in df.columns]\n    driver_columns = [col for col, col_type in all_columns_dict.items() \n                      if col_type == \"DRIVERS\" and col in df.columns]\n    \n    # Standard columns to include\n    standard_columns = [col for col, col_type in all_columns_dict.items() \n                       if col_type == \"STANDARD\" and col in df.columns]\n    \n    # Auto-added columns to include\n    auto_added_columns = ['Survey_Name', 'Processed_Date']\n    available_auto_added = [col for col in auto_added_columns if col in df.columns]\n    \n    # Combine all relevant columns\n    relevant_columns = list(set(standard_columns + ltr_columns + driver_columns + available_auto_added))\n    \n    if len(ltr_columns) > 0 or len(driver_columns) > 0:\n        subset_df = df[relevant_columns].copy()\n        print(f\"    Extracted LTR/Driver data: {len(ltr_columns)} LTR columns, {len(driver_columns)} driver columns\")\n        print(f\"    LTR columns: {ltr_columns}\")\n        print(f\"    Driver columns: {driver_columns}\")\n        return subset_df\n    else:\n        print(f\"    No LTR or driver columns found in {survey_name}\")\n        return None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Generating output files...\\n\")\n\n# Output 1: Combined LTR and Driver Scores\nif nps_driver_data:\n    combined_ltr_drivers = pd.concat(nps_driver_data, ignore_index=True, sort=False)\n    ltr_output_file = os.path.join(OUTPUT_DIR, f\"Combined_LTR_Drivers_{TIMESTAMP}.csv\")\n    combined_ltr_drivers.to_csv(ltr_output_file, index=False)\n    print(f\"✓ LTR & Driver Scores: {ltr_output_file}\")\n    print(f\"  - Total records: {len(combined_ltr_drivers)}\")\n    print(f\"  - Surveys included: {combined_ltr_drivers['Survey_Name'].nunique()}\")\n    print(f\"  - Columns: {len(combined_ltr_drivers.columns)}\")\nelse:\n    print(\"✗ No LTR/Driver data found across surveys\")\n\nprint()\n\n# Output 2: All Survey Data Combined\nif all_survey_data:\n    combined_all_data = pd.concat(all_survey_data, ignore_index=True, sort=False)\n    all_data_output_file = os.path.join(OUTPUT_DIR, f\"Combined_All_Surveys_{TIMESTAMP}.csv\")\n    combined_all_data.to_csv(all_data_output_file, index=False)\n    print(f\"✓ All Survey Data: {all_data_output_file}\")\n    print(f\"  - Total records: {len(combined_all_data)}\")\n    print(f\"  - Surveys included: {combined_all_data['Survey_Name'].nunique()}\")\n    print(f\"  - Total columns: {len(combined_all_data.columns)}\")\nelse:\n    print(\"✗ No survey data processed successfully\")\n\nprint()\n\n# Output 3: Processing Summary\nsummary_df = pd.DataFrame(processing_summary)\nsummary_output_file = os.path.join(OUTPUT_DIR, f\"Processing_Summary_{TIMESTAMP}.csv\")\nsummary_df.to_csv(summary_output_file, index=False)\nprint(f\"✓ Processing Summary: {summary_output_file}\")\nprint(f\"  - Surveys processed: {len(summary_df)}\")\nprint(f\"  - Successful: {len(summary_df[summary_df['Processing_Status'] == 'Success'])}\")\nprint(f\"  - Failed: {len(summary_df[summary_df['Processing_Status'] != 'Success'])}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display processing summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_df = pd.DataFrame(processing_summary)\n",
    "print(summary_df[['Survey_Name', 'Records_Processed', 'Processing_Status']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal records processed: {summary_df['Records_Processed'].sum()}\")\n",
    "print(f\"Average records per survey: {summary_df['Records_Processed'].mean():.1f}\")\n",
    "print(f\"Success rate: {len(summary_df[summary_df['Processing_Status'] == 'Success']) / len(summary_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "if all_survey_data:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA QUALITY CHECKS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    combined_data = pd.concat(all_survey_data, ignore_index=True, sort=False)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_summary = combined_data.isnull().sum()\n",
    "    print(f\"Columns with missing values: {len(missing_summary[missing_summary > 0])}\")\n",
    "    \n",
    "    # Check for duplicate ResponseIDs within surveys\n",
    "    duplicate_check = combined_data.groupby('Survey_Name')['ResponseID'].apply(lambda x: x.duplicated().sum() if 'ResponseID' in combined_data.columns else 0)\n",
    "    print(f\"Surveys with duplicate ResponseIDs: {len(duplicate_check[duplicate_check > 0])}\")\n",
    "    \n",
    "    # Data type summary\n",
    "    print(f\"Total unique columns across all surveys: {len(combined_data.columns)}\")\n",
    "    print(f\"Numeric columns: {len(combined_data.select_dtypes(include=[np.number]).columns)}\")\n",
    "    print(f\"Text columns: {len(combined_data.select_dtypes(include=['object']).columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Custom Transformations\n",
    "Update the \"CUSTOM TRANSFORMATIONS SECTION\" in the processing loop above with:\n",
    "- Data cleaning rules specific to your surveys\n",
    "- Column standardization and renaming\n",
    "- Calculated fields and derived metrics\n",
    "- Data validation and quality checks\n",
    "\n",
    "### Database Configuration\n",
    "Update the `execute_query_and_load_data` function with your actual database connection details:\n",
    "- Database type (PostgreSQL, SQL Server, MySQL, etc.)\n",
    "- Connection parameters\n",
    "- Authentication details\n",
    "\n",
    "### Output Customization\n",
    "Modify the output generation section to:\n",
    "- Add additional output formats (Excel, JSON, etc.)\n",
    "- Create survey-specific outputs\n",
    "- Generate summary reports and visualizations\n",
    "\n",
    "### File Organization\n",
    "Ensure your SQL files are organized as:\n",
    "```\n",
    "data/raw/\n",
    "├── PRISM.sql\n",
    "├── Customer_Satisfaction_Q1.sql\n",
    "├── Employee_Engagement_2024.sql\n",
    "└── ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}